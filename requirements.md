# Выполнение задания

Задание выполнено с помощью следующих технологий:
* Python;
* TSQL;
* Postgre;
* Airflow;
* Docker.

Для запуска учебной инфраструктуры клонируйте к себе на ПК репозиторий:

    git clone https://github.com/xxxRichiexxx/Neoflex_1

Далее выполните из папки "Neoflex_1" следующую комманду:

    docker-compose up -d --build

После запуска данной комманды будет развернуто несколько контейнеров: 

* Airflow с базой метаданных Postgres;
* КХД на базе Postgres.

Папки "Neoflex_1/Data" и "Neoflex_1/dags" смонтированы в контейнер Airflow, т.е все скрипты, размещенные в папке dags, доступны для Airflow, все файлы с данными для загрузки в папке data доступны для Airflow.

Подключитесь к контейнеру DWH с помощью Debeaver:

    login: de
    password: de

![image info](https://github.com/xxxRichiexxx/NEOFLEX_1/blob/main/img/Debeaver.PNG)

Примените в базе данных bank следующие скрипты "Neoflex_1/DDL.sql".

Зайдите в Airflow по следующей ссылке:

    http://localhost/home

Введите логин и пароль:

    login: airflow
    password: airflow

Создайте в Airflow подключение к DWH:

![image info](https://github.com/xxxRichiexxx/NEOFLEX_1/blob/main/img/Airflow.PNG)

Запустите DAGи.

При выполнении задания использовался следующий подход:

* Все исходные данные из формата csv сначала загружаются в слой raw без изменений. Данный слой разработан таким образом, чтобы минимизировать проблемы при загрузке данных в хранилище и избежать повторных запросов данных в источнике;
* Далее данные из слоя raw загружаются в слой ODS и слой DDS. Два слоя созданы для того, чтобы продемонстрировать два решения поставленной задачи. В первом решении данные загружаются в хранилище с предварительной очисткой, преобразованием форматов, но без создания связей в целевых таблицах. Для демонстрации данного решения создан слой ODS. Во втором решении данные загружаются в хранилище с предварительной очисткой, преобразованием форматов и созданием связей между целевыми таблицами с помощью сурогатных ключей. Данное решение продемонстрированно в слое DDS.

Для загрузки данных в слой raw используются динамические DAG (см. dags/to_raw_dag.py).
Данный скрипт генерирует DAGи на основе yaml-файла (см. dags/to_raw_dag_config.yaml): для каждого csv-файла свой DAG.

После окончания загрузки данных в raw-слой начинают работать DAGи, загружающие данные в слои ODS и DDS (см. dags/to_ods_dag.py и dags/to_dds_dag.py). Данные DAGи ожидают окончания загрузки данных в raw с помощью ExternalTaskSensor.

Т.к ODS-слой не предполагает связей между таблицами(конкретно в данном случае), то загрузка данных осуществляется параллельно во все целевые таблицы. 

Т.к загрузка данных в DDS-слой предполагает создание связей между таблицами, то загрузка осуществляется в определенном порядке:

![image info](https://github.com/xxxRichiexxx/NEOFLEX_1/blob/main/img/dag.PNG)

Модель слоя DDS выглядит следующим образом:

![image info](https://github.com/xxxRichiexxx/NEOFLEX_1/blob/main/img/ERD.PNG)

Работа дагов логируется средствами Airflow и по заданию происходит запись логов в специальную таблицу LOGS.DAG_LOGS.

![image info](https://github.com/xxxRichiexxx/NEOFLEX_1/blob/main/img/Logs.PNG)

Кроме того, данные, не загруженные в слой DDS (из-за невыполнения ограничений) копируются в слой REJECTED_DATA.